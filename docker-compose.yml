services:
  comfyui-backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: comfyui-swarmui-backend
    ports:
      - "3000:3000"  # ComfyUI port as per RunPod
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONUNBUFFERED=1
      - HF_HOME=/workspace
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - HF_XET_CHUNK_CACHE_SIZE_BYTES=90737418240
    volumes:
      # ComfyUI model storage
      - comfyui_models:/workspace/ComfyUI/models
      - comfyui_output:/workspace/ComfyUI/output
      - comfyui_input:/workspace/ComfyUI/input
      - comfyui_custom_nodes:/workspace/ComfyUI/custom_nodes
      # HuggingFace cache
      - huggingface_cache:/workspace
      # Logs and configs
      - ./configs:/workspace/configs:ro
      - ./logs:/workspace/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/system_stats"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    # Labels for Coolify
    labels:
      - "coolify.managed=true"
      - "coolify.name=comfyui-swarmui-backend"
      - "coolify.type=service"
      - "traefik.enable=true"
      - "traefik.http.routers.comfyui.rule=Host(`comfyui.${DOMAIN:-localhost}`)"
      - "traefik.http.services.comfyui.loadbalancer.server.port=3000"

volumes:
  comfyui_models:
    driver: local
  comfyui_output:
    driver: local
  comfyui_input:
    driver: local
  comfyui_custom_nodes:
    driver: local
  huggingface_cache:
    driver: local

networks:
  default:
    name: coolify
    external: true
